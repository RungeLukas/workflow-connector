# Signavio Workflow Accelerator Connector

The Workflow Accelerator Connector is a RESTful web service which acts as a proxy between Signavio's Workflow Accelerator and an external SQL database.

![Overview](https://cip.li/res/wfa-connector-overview.png)

In order to use the connector with Signavio's Workflow Accelerator, the connector must first be running on a server that is accessible to the public internet. After the connector is running and the databases have been provisioned, a Workflow Accelerator administrator can [add](https://docs.signavio.com/userguide/workflow/en/integration/connectors.html#configuring-a-connector) the connector to a workspace under _Services & Connector_. A process owner can then use the connector in a process to populate a drop down field dynamically using data from the database. More information about this can be found [here](https://docs.signavio.com/userguide/workflow/en/integration/connectors.html)

## Features

- Insert, update and delete table rows using a standard RESTful API
- Supports multiple databases (MicrosoftSQL Server, Sqlite3, MySQL, PostgresSQL)

## Installation

The connector is written in [go](https://golang.org) and can be downloaded from the [release page](TODO) for linux and windows platforms. Alternatively, the executable (`workflow-connector`) can be generated by compiling the source code [locally](#Install_from_source_(on_linux)), after resolving all package dependencies, or [in a docker container](#Install_from_source_(using_docker)). If you decide to compile the executable yourself and are not well versed with go, then it is recommended to generate the executable file in a docker container.

### Install from source (on linux)
1. Download and install go from your distrubtion's package manager (for ubuntu `apt-get install go`) and make sure you are using version >= 1.9
2. Download and install the workflow-connector using the `go get` command on the command line. The workflow-connector source code and all dependencies will be downloaded to the location pointed to by your `$GOPATH` environment variable. Here we assume that this is located in `~/go`.
```sh
$ go get -v github.com/signavio/workflow-connector
```

### Install from source (using docker)


## Deployment

### Regular server (bare metal)

The architecture specific executable file, and related configuration files, can simply be copied to a directory on the server where it should be run. The following code snippets demonstrate how this can be done in an ubuntu linux environment.

1. First, create the necessary directories.

```sh
# first create the necessary directories
#
$ mkdir -p ~/.config/workflow-connector
#
# then copy the executable file to a 
# directory located in your $PATH. Here
# we assume that ~/bin is in $PATH and 
# that the exectuable file has already
# been downloaded from github
#
$ cp 

```
2. Copy the executable file to a directory located in your `$PATH`. Here we assume that `~/bin` is in your `$PATH` and that the executable file has already been downloaded from github using `go get -v github.com/signavio/workflow-connector`. Afterwards

```sh
# We assume $GOPATH is set to ~/go
$ cp ~/go/github.com/signavio/workflow-connector/bin/amd64/linux/workflow-connector ~/bin/
# Copy the configuration files
$ cp ~/go/github.com/signavio/workflow-connector/bin/amd64 
```
### Containerized (using docker)

## Configuration

All program configuration settings (like database connection information, username, password, etc.) should be saved in a `config.yaml` file that is located in the same directory as the executable, or in one of the following directories:

| **Linux**                    |
|------------------------------|
| ./config/                    |
| /etc/                        |
| ~/.config/workflow-connector |

All settings may instead be configured using the system's environment variables. For example, you can specify the database connection url by exporting the environment variable `DATABASE_URL=sqlserver://john:84mj29rSgHz@172.17.8.2?database=test`. This means that nested fields in the yaml file should be delimited with a '_' (underscore) character when used in an environment variable. All configuration settings declared via environment variables will take precedence over the settings in your `cofig.yaml` file.

## Example (using heroku)

The following [screencast](https://drive.google.com/file/d/1V8Kizoka-5L-56SpqTRxshCBBDyerB7v/view?usp=sharing) shows you how to install and configure the workflow database connector using Heroku.

## Example (using sqlite)

This example will assume you are running in a linux environment (using a ubuntu distro) and are using a sqlite database located in the same directory as the executable.

### Prerequisites

1. Download this github repository to a local directory on your computer 

```bash
$ git clone https://github.com/signavio/wfa-connector && cd wfa-connector
```

2. Download and install sqlite and golang

```bash
$ apt-get install sqlite go
```

3. Create the database file
```bash
$ touch test.db
```

### Populate the database

For testing purposes, we will create a table called `equipment` and populate it with data. The table will end up looking like this: 

**Equipment**

| id | name                           | acquisition_cost | purchase_date       |
|----|--------------------------------|------------------|---------------------|
|  1 | Stainless Steel Cooling Spiral |            119.0 | 2017-09-07 12:00:00 |
|  2 | Fermentation Tank (50L)        |            250.0 | 2014-09-07 11:00:00 |
|  3 | Temperature Gauge              |            49.99 | 2017-09-04 11:00:00 |
|  4 | Masch Tun (50L)                |           199.99 | 2016-09-04 11:00:00 |


We can accomplish this by writing the necessary sql statements to a temporary file and then import the file into a sqlite database.

```bash
$ echo "\
CREATE TABLE IF NOT EXISTS equipment ( \
id integer not null primary key, \
name text, \
acquisition_cost real, \
purchase_date datetime); \
INSERT INTO equipment(id, name, acquisition_cost, purchase_date) \
VALUES \
(1,'Stainless Steel Cooling Spiral',119.0,'2017-09-07 12:00:00'), \
(2,'Fermentation Tank (50L)',250.0,'2014-09-07 11:00:00'), \
(3,'Temperature Gauge',49.99,'2017-09-04 11:00:00'), \
(4,'Masch Tun (50L)',199.99,'2016-09-04 11:00:00'); \
" > /tmp/test.db
```

```bash
$ sqlite3 test.db < /tmp/test.db
```

The table should now look like this: 

```sqlite
$ sqlite3 test.db
SQLite version 3.20.1 2017-08-24 16:21:36
Enter ".help" for usage hints.
sqlite> SELECT * FROM equipment;
1|Stainless Steel Cooling Spiral|119.0|2017-09-07 12:00:00
2|Fermentation Tank (50L)|250.0|2014-09-07 11:00:00
3|Temperature Gauge|49.99|2017-09-04 11:00:00
4|Masch Tun (50L)|199.99|2016-09-04 11:00:00
sqlite> .quit
$ 
```

Now exit out of the sqlite command line interface (using the command `.quit`)

### Run the workflow connector

Before running the `workflow-connector` command, you should either edit the `config.yaml` file to include the database connection parameters and other settings, or export these settings as environment variables. Running the `workflow-connector` command will then listen on the specified port (here port 8080) for inbound HTTP Requests.

```sh
# Export environment variables
#
$ export PORT=:8080 DATABASE_URL=test.db DATABASE_DRIVER=sqlite3
#
# Run the connector
$ ./workflow-connector
Listening on :8080

```

### Test the REST API

Now we can test the functionality of the connector's REST API either in a new terminal, or using the following the postman collection.

Go ahead and fetch the product with id 1 by sending a `HTTP GET` request to the connector using the `curl` command (you can `apt-get install curl` if `curl` is not yet installed):

```bash
$ curl --verbose --request GET http://localhost:8080/products/1
# Response:
## Headers
> GET /products HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.56.1
> Accept: */*
>
< HTTP/1.1 200 OK
< Content-Type: application/json
< Date: Mon, 13 Nov 2017 15:10:03 GMT
< Content-Length: 60
<
## Data
{
  "id": "1",
  "price": 2,
  "product_name": "Club-Mate"
}
$
```

You will see that the webservice returned the product with id 1 as `application/JSON`

#### Insert a new product in the database

You can create a new product by sending a `HTTP POST` to the webservice

```bash
$ curl --verbose --request POST --header "Content-Type: application/x-www-form-urlencoded" --data "price=0.84&product_name=Schlenkerla+Rauchbier" http://localhost:3000/products
# Response:
## Headers
> POST /products HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.56.1
> Accept: */*
> Content-Type: application/x-www-form-urlencoded
> Content-Length: 45
>
* upload completely sent off: 45 out of 45 bytes
< HTTP/1.1 200 OK
< Content-Type: application/json
< Date: Mon, 13 Nov 2017 15:12:33 GMT
< Content-Length: 2
<
## Data
{}
$
```

Let's verify that the new product was inserted into the database

```bash
$ curl --request GET http://localhost:8080/products/4
# Response:
{
  "id": "4",
  "price": 0.84,
  "product_name": "Schlenkerla Rauchbier"
}
$
```

#### Updating an existing product

You may be thinking, a delicious, franconian Rauchbier definitely costs more than .84â‚¬, and you would be right. So let's adjust that price to something more realistic by sending a `HTTP PUT` with the new price.

```bash
$ curl --verbose --request PUT --data "price=1.25" http://localhost:8080/products/4
# Response:
{}

# Now verify the new price
$ curl --request GET http://localhost:8080/products/4
# Response: 
{
  "id": "4",
  "price": 1.25,
  "product_name": "Schlenkerla Rauchbier"
}
$
```

#### Deleting an existing product

TODO: deletion is not supported at the moment.

## Technical Overview

The following diagram shows the main components used in the workflow connector. The following list shows, at a high level, how an HTTP request is handled and how data is sent back to the user from the database.



![Program Execution](https://cip.li/res/wfa-connector.png)

**Entrypoint**: the `main()` function in the `./server.go` file.
### [010] load configuration settings

#### Source:

```go
      cfg := config.Load()
```

#### Description:

- The workflow-connector uses the `github.com/spf13/viper` dependency to load configuration settings from a file, environment variables or an external key-value store. `github.com/spf13/viper` is also used by many other go projects ([rkt](https://coreos.com/rkt/), [kubernetes](https://kubernetes.io), and others) to load configuration settings.

### [020] create new endpoint

#### Source:

```go
     endpoint, err := endpoints.NewEndpoint(cfg)
     if err != nil {
     log.Fatalf("%s", err)
     }
 ``` 
 #### Description:
 
 - Here we create a new endpoint like its no ones business.
 
## Support

Any inquiries for support can be sent to [support](mailto:support@signavio.com). 

## Authors

The development team at Signavio with input from Stefano Da Ros and Peter Hilton 

## Licence

Apache License 2.0
